#统计分析
##自我报告：11个问卷和5个领域量表得分(data_al[, 1:16])
##认知任务：3个行为实验共14个指标(data_al[, 17:30])

#加载分析所用的包
```{r}
#if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  psych, lavaan, ggplot2, reshape2, caret,
  FactoMineR, factoextra, tidyverse, linkET,
  vegan, ggnewscale, RColorBrewer, EGAnet, xgboost
)
```

#数据标准化处理
```{r}
#计算各问卷总分和认知任务相关的z分数
data_al <- all_data_cleaned%>%
  select(matches("_al$"), -starts_with(c("phq", "gad", "SGPS", "swb","domain")),c("Ability","Attraction","Wealth","Social","Moral","obj_ses1",'fri_ses2',"ability_ALT_rt","moral_ALT_rt","ability_ALT_d","moral_ALT_d","ability_IAT","moral_IAT","ability_SRET_EW","moral_SRET_EW","ability_SRET_rt","moral_SRET_rt","ability_SRET_RJ1_d","moral_SRET_RJ1_d","ability_SRET_RJ2_d","moral_SRET_RJ2_d"),-"obj_ses1",-"fri_ses2")
data_al <- scale(data_al)
write.csv(data_al,"data_al_z.csv")
```

#问卷报告与认知任务相关性分析
```{r}
#自我报告+认知任务
cor_matrix <- cor(data_al, method = "pearson")  # 可选方法：pearson/spearman/kendall
corrplot(
  cor_matrix, 
  method = "color", 
  type = "upper", 
 tl.col = "black", 
 tl.srt = 45,
 diag = FALSE,
  col = colorRampPalette(c("blue", "white", "red"))(20),
  title = "相关系数热图"
)
```

#自我报告
```{r}
cor_matrix <- cor(data_al[,1:16], method = "pearson")  # 可选方法：pearson/spearman/kendall
corrplot(
  cor_matrix, 
  method = "color", 
  type = "upper", 
 tl.col = "black", 
 tl.srt = 45,
 diag = FALSE,
  col = colorRampPalette(c("blue", "white", "red"))(20),
  title = "自我报告相关系数热图"
)
```

#认知任务
```{r}
cor_matrix <- cor(data_al[, 17:30], method = "pearson")  # 可选方法：pearson/spearman/kendall
corrplot(
  cor_matrix, 
  method = "color", 
  type = "upper", 
 tl.col = "black", 
 tl.srt = 45,
 diag = FALSE,
  col = colorRampPalette(c("blue", "white", "red"))(20),
  title = "认知任务相关系数热图"
)
```

#保留一个变量时其他变量的预测程度（10折交叉验证）
```{r}
# 获取所有变量名
variables <- setdiff(names(data_z_cleaned), c("X.1", "X"))
# 初始化一个列表来保存模型结果
model_results <- list()
# 设置交叉验证的参数
control <- trainControl(method = "cv", number = 10) # 10折交叉验证
# 循环遍历每个变量
for(target_var in variables) {
# 排除当前目标变量，获取预测变量
  predictors <- setdiff(variables, target_var)
# 创建公式
  formula <- as.formula(paste(target_var, "~", paste(predictors, collapse = "+")))
# 训练模型，这里使用线性回归作为示例，你可以根据需要更换为其他模型
  model <- train(formula, data = data_z_cleaned, method = "lm", trControl = control)
# 保存模型结果
  model_results[[target_var]] <- model
}
# 输出每个模型的性能
for(target_var in names(model_results)) 
  cat("Model performance for", target_var, ":\n")
  print(model_results[[target_var]])
# 初始化一个数据框来保存所有模型的性能指标
performance_df <- data.frame(Target_Variable = character(),
                             RMSE = numeric(),
                             Rsquared = numeric(),
                             MAE = numeric(),
                             stringsAsFactors = FALSE)
# 提取每个模型的性能指标
for(target_var in names(model_results)) {
  # 提取性能指标
  results <- model_results[[target_var]]$results
  rmse <- ifelse(exists("RMSE", results), results$RMSE, NA)
  rsquared <- ifelse(exists("Rsquared", results), results$Rsquared, NA)
  mae <- ifelse(exists("MAE", results), results$MAE, NA)
# 将性能指标添加到数据框
  performance_df <- rbind(performance_df, data.frame(Target_Variable = target_var,
                                                     RMSE = rmse,
                                                     Rsquared = rsquared,
                                                     MAE = mae,
                                                     stringsAsFactors = FALSE))
}

# 将数据框写入 CSV 文件
write.csv(performance_df, "model_performance.csv", row.names = FALSE)
# 读取之前保存的性能指标数据框
performance_df <- read.csv("model_performance.csv")

# 创建RMSE的条形图
ggplot(performance_df, aes(x = reorder(Target_Variable, RMSE), y = RMSE)) +
  geom_bar(stat = "identity") +
  coord_flip() + # 翻转坐标轴，使得变量名更容易阅读
  labs(x = "Target Variable", y = "RMSE", title = "Root Mean Squared Error for Each Model") +
  theme_minimal()

# 创建R-squared的条形图
ggplot(performance_df, aes(x = reorder(Target_Variable, Rsquared), y = Rsquared)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(x = "Target Variable", y = "R-squared", title = "R-squared for Each Model") +
  theme_minimal()

# 创建MAE的条形图
ggplot(performance_df, aes(x = reorder(Target_Variable, MAE), y = MAE)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(x = "Target Variable", y = "MAE", title = "Mean Absolute Error for Each Model") +
  theme_minimal()
```

##对自我报告与认知任务分别降维(PCA)
#自我报告
```{r}
# 如未安装需要先安装所需的包
#install.packages("FactoMineR")
#install.packages("factoextra") # 用于结果的可视化

# 读取CSV文件
pca_q <- data_al[, 1:16]
#进行PCA降维处理
pca_q_result <- PCA(pca_q, graph = FALSE)
# 查看PCA结果
print(pca_q_result)
# 查看所有主成分
print(pca_q_result$eig)
# 生成碎石图
fviz_eig(pca_q_result, addlabels = TRUE, ylim = c(0, max(pca_q_result$eig) + 0.1 * max(pca_q_result$eig)))
#使用factoextra包进行结果的可视化
fviz_pca_ind(pca_q_result, col.ind = "cos2", 
              gradient.cols = c("blue", "red"), 
              repel = TRUE # Avoid text overlapping
)
pca_q_scores <- as.data.frame(pca_q_result$ind$coord)
write.csv(pca_q_scores, "PCA1.csv", row.names = FALSE)
```
#聚类+网络热图
```{r}
#由于mantel检验无法对负值进行分析，因此在此步骤将计算z分数后的问卷总分进行平方处理
# 对data_al中的每个元素取平方
data_q_squared <- data_al[,1:16] ^ 2

# 重命名数据框为data_q_adjusted
data_q_adjusted <- data_q_squared
dist_q1 <- dist(data_q_adjusted, method = "euclidean")

# 对问卷做聚类（按列）
dist_col <- dist(t(data_q_adjusted), method = "euclidean")
hc <- hclust(dist_col, method = "ward.D2")
clusters <- cutree(hc, k = 3)

# 构建 spec_select
spec_select <- split(1:ncol(data_q_adjusted), clusters)
names(spec_select) <- paste0("Cluster_", 1:length(spec_select))

# 构建 Mantel 输入（分别是距离矩阵）
spec_dist <- dist(t(data_q_adjusted), method = "euclidean")  # 每个问卷是一个“样本”
env_dist <- dist(t(data_q_adjusted), method = "euclidean")

# 执行 Mantel 检验（每个问卷 vs 每个聚类）
mantel <- mantel_test(
  spec = data_q_adjusted,
  env = data_q_adjusted,
  spec_select = spec_select
) %>%
  mutate(
    rd = cut(r, breaks = c(-Inf, 0.2, 0.3, Inf),
             labels = c("< 0.2", "0.2 - 0.3", ">= 0.3")),
    pd = cut(p, breaks = c(-Inf, 0.005, 0.01, 0.05, Inf),
             labels = c("< 0.005", "0.005 - 0.01", "0.01 - 0.05", ">= 0.05"))
  )

# 计算相关矩阵
cor_matrix <- correlate(data_q_adjusted)

# 绘图
p <- qcorrplot(cor_matrix, type = "upper", diag = FALSE, grid_col = NA) +
  geom_point(shape = 21, size = 8, fill = NA, stroke = 0.35, color = "black") +
  geom_point(aes(size = abs(r), fill = r),
             shape = 21, stroke = 0.35, color = "black") +
  scale_size(range = c(1, 8), guide = "none") +
  new_scale("size") +
  geom_couple(data = mantel,
              aes(color = pd, size = rd),
              label.size = 3.88,
              label.family = "",
              label.fontface = 1,
              nudge_x = 0.2,
              curvature = nice_curvature(by = "from")) +
  scale_fill_gradientn(
    limits = c(-0.8, 0.8),
    breaks = seq(-0.8, 0.8, 0.4),
    colors = rev(brewer.pal(11, "Spectral"))
  ) +
  scale_size_manual(values = c(0.2, 0.7, 1.2)) +
  scale_color_manual(values = color_pal(4, alpha = 0.6)) +
  guides(
    size = guide_legend(title = "Mantel's r", order = 2, keyheight = unit(0.5, "cm")),
    colour = guide_legend(title = "Mantel's p", order = 1, keyheight = unit(0.5, "cm")),
    fill = guide_colorbar(title = "Pearson's r", keyheight = unit(2.2, "cm"), keywidth = unit(0.5, "cm"), order = 3)
  ) +
  theme(legend.box.spacing = unit(0, "pt"))
# 保存图像
ggsave(p, filename = "Cluster_Correlation_with_Mantel（1）.pdf", width = 9, height = 6)
```

#认知任务
```{r}
# 读取CSV文件
pca_task <- data_al[,17:30]
# 进行PCA降维处理
pca_task_result <- PCA(pca_task, graph = FALSE)
# 查看PCA结果
print(pca_task_result)
# 查看所有主成分
print(pca_task_result$eig)
# 生成碎石图
fviz_eig(pca_task_result, addlabels = TRUE, ylim = c(0, max(pca_task_result$eig) + 0.1 * max(pca_task_result$eig)))
#使用factoextra包进行结果的可视化
fviz_pca_ind(pca_task_result, col.ind = "cos2", 
              gradient.cols = c("blue", "red"), 
              repel = TRUE # Avoid text overlapping
)
pca_task_scores <- as.data.frame(pca_task_result$ind$coord)
write.csv(pca_task_scores, "PCA2.csv", row.names = FALSE)
```

#聚类+网络热图
```{r}
#由于mantel检验无法对负值进行分析，因此在此步骤将计算z分数后的问卷总分进行平方处理
# 对data_al中的每个元素取平方
data_q_squared <- data_al[,17:30] ^ 2

# 重命名数据框为data_q_adjusted
data_q_adjusted <- data_q_squared
dist_q1 <- dist(data_q_adjusted, method = "euclidean")

# 对问卷做聚类（按列）
dist_col <- dist(t(data_q_adjusted), method = "euclidean")
hc <- hclust(dist_col, method = "ward.D2")
clusters <- cutree(hc, k = 3)

# 构建 spec_select
spec_select <- split(1:ncol(data_q_adjusted), clusters)
names(spec_select) <- paste0("Cluster_", 1:length(spec_select))

# 构建 Mantel 输入（分别是距离矩阵）
spec_dist <- dist(t(data_q_adjusted), method = "euclidean")  # 每个问卷是一个“样本”
env_dist <- dist(t(data_q_adjusted), method = "euclidean")

# 执行 Mantel 检验（每个问卷 vs 每个聚类）
mantel <- mantel_test(
  spec = data_q_adjusted,
  env = data_q_adjusted,
  spec_select = spec_select
) %>%
  mutate(
    rd = cut(r, breaks = c(-Inf, 0.2, 0.3, Inf),
             labels = c("< 0.2", "0.2 - 0.3", ">= 0.3")),
    pd = cut(p, breaks = c(-Inf, 0.005, 0.01, 0.05, Inf),
             labels = c("< 0.005", "0.005 - 0.01", "0.01 - 0.05", ">= 0.05"))
  )

# 计算相关矩阵
cor_matrix <- correlate(data_q_adjusted)

# 绘图
p <- qcorrplot(cor_matrix, type = "upper", diag = FALSE, grid_col = NA) +
  geom_point(shape = 21, size = 8, fill = NA, stroke = 0.35, color = "black") +
  geom_point(aes(size = abs(r), fill = r),
             shape = 21, stroke = 0.35, color = "black") +
  scale_size(range = c(1, 8), guide = "none") +
  new_scale("size") +
  geom_couple(data = mantel,
              aes(color = pd, size = rd),
              label.size = 3.88,
              label.family = "",
              label.fontface = 1,
              nudge_x = 0.2,
              curvature = nice_curvature(by = "from")) +
  scale_fill_gradientn(
    limits = c(-0.8, 0.8),
    breaks = seq(-0.8, 0.8, 0.4),
    colors = rev(brewer.pal(11, "Spectral"))
  ) +
  scale_size_manual(values = c(0.2, 0.7, 1.2)) +
  scale_color_manual(values = color_pal(4, alpha = 0.6)) +
  guides(
    size = guide_legend(title = "Mantel's r", order = 2, keyheight = unit(0.5, "cm")),
    colour = guide_legend(title = "Mantel's p", order = 1, keyheight = unit(0.5, "cm")),
    fill = guide_colorbar(title = "Pearson's r", keyheight = unit(2.2, "cm"), keywidth = unit(0.5, "cm"), order = 3)
  ) +
  theme(legend.box.spacing = unit(0, "pt"))
# 保存图像
ggsave(p, filename = "Cluster_Correlation_with_Mantel（2）.pdf", width = 9, height = 6)
```

#对自我报告与认知任务的网络分析
```{r}
# Step 1: 数据准备
network_data1 <- data_al[, 1:16]  # 第一组数据
network_data2 <- data_al[, 17:30]  # 第二组数据
# Step 2: 网络分析
ega_model1 <- EGA(network_data1, model = "glasso")  # 第一组数据网络分析
ega_model2 <- EGA(network_data2, model = "glasso")  # 第二组数据网络分析
# 提取邻接矩阵
adj_matrix1 <- ega_model1$network  # 第一组网络邻接矩阵
adj_matrix2 <- ega_model2$network  # 第二组网络邻接矩阵
# Step 3: 合并网络
combined_matrix <- matrix(0, nrow = ncol(network_data1) + ncol(network_data2), 
                          ncol = ncol(network_data1) + ncol(network_data2))
rownames(combined_matrix) <- c(colnames(network_data1), colnames(network_data2))
colnames(combined_matrix) <- c(colnames(network_data1), colnames(network_data2))
# 填充邻接矩阵
combined_matrix[1:ncol(network_data1), 1:ncol(network_data1)] <- adj_matrix1
combined_matrix[(ncol(network_data1) + 1):nrow(combined_matrix), 
                (ncol(network_data1) + 1):ncol(combined_matrix)] <- adj_matrix2
# Step 4: 可视化
groups <- list(
  'Questionnaire' = 1:ncol(network_data1),
  'Task' = (ncol(network_data1) + 1):ncol(combined_matrix)
)

pdf('Network_UpDown.pdf')
qgraph(
  combined_matrix,
  groups = groups,
  layout = layout,        # 自定义布局：上下分布
  labels = FALSE,         # 不显示节点上的数字
  legend = TRUE,          # 显示图例
  label.cex = 0.8,        # 标签大小
  vsize = 5,              # 节点大小
  curveAll = TRUE,        # 显示所有边的曲率
  curve = 0.8,            # 边曲率
  edge.color = "black",   # 边的颜色
  color = c("#add3f4", "#fccb8e"),  # 第一组蓝色，第二组橙色
  theme = "colorblind",   # 色盲友好的主题
  title = "Network: Questionnaire and Task"
)
dev.off()
```

#对现实结果的预测：抑郁/焦虑/拖延/主观幸福感
##机器学习方法
###梯度提升机XGBoost：XGBoost迭代的机器学习技术，通过逐步添加新的模型（通常是弱学习器，如决策树）来修正现有模型的残差，从而提高整体模型的预测能力，是一种优化的分布式梯度提升决策树算法，在梯度提升框架下构建的，专门设计用于提高计算效率和模型性能，尤其在处理大规模数据集时表现优异。

#自我报告问卷
```{r}
#SGPS
# 准备数据
X <- as.matrix(pca_q_scores[, c("Dim.1", "Dim.2", "Dim.3", "Dim.4", "Dim.5")])
y <- health_var$SGPS
dtrain <- xgb.DMatrix(data = X, label = y)
#选择最佳参数
#max_depths <- c(3, 6, 9)
#etas <- c(0.01, 0.1, 0.3)
#nrounds <- c(50, 100, 200)

# 训练模型：max_depth 决策树的最大深度；eta 学习率（学习速度）；nrounds 迭代次数；
xgb_model1 <- xgboost(data = dtrain, max_depth = 6, eta = 0.1, nrounds = 100, objective = "reg:squarederror")
#查看哪些特征对预测影响最大
xgb.importance(feature_names = colnames(X), model = xgb_model1)
# 预测可视化
predictions_q_SGPS <- predict(xgb_model1, dtrain)
# 制作数据框用于绘图
results_q_SGPS <- data.frame(
  actual = y,
  predicted = predictions_q_SGPS
)
```

```{r}
#phq
X <- as.matrix(pca_q_scores[, c("Dim.1", "Dim.2", "Dim.3", "Dim.4", "Dim.5")])
y <- health_var$phq
dtrain <- xgb.DMatrix(data = X, label = y)
xgb_model2 <- xgboost(data = dtrain, max_depth = 6, eta = 0.1, nrounds = 100, objective = "reg:squarederror")
xgb.importance(feature_names = colnames(X), model = xgb_model2)
# 预测可视化
predictions_q_phq <- predict(xgb_model2, dtrain)
# 制作数据框用于绘图
results_q_phq <- data.frame(
  actual = y,
  predicted = predictions_q_phq
)
```

```{r}
#gad
X <- as.matrix(pca_q_scores[, c("Dim.1", "Dim.2", "Dim.3", "Dim.4", "Dim.5")])
y <- health_var$gad
dtrain <- xgb.DMatrix(data = X, label = y)
xgb_model3 <- xgboost(data = dtrain, max_depth = 6, eta = 0.1, nrounds = 100, objective = "reg:squarederror")
xgb.importance(feature_names = colnames(X), model = xgb_model3)
# 预测可视化
predictions_q_gad <- predict(xgb_model3, dtrain)
# 制作数据框用于绘图
results_q_gad <- data.frame(
  actual = y,
  predicted = predictions_q_gad
)
```

```{r}
#SWB
X <- as.matrix(pca_q_scores[, c("Dim.1", "Dim.2", "Dim.3", "Dim.4", "Dim.5")])
y <- health_var$SWB
dtrain <- xgb.DMatrix(data = X, label = y)
xgb_model4 <- xgboost(data = dtrain, max_depth = 6, eta = 0.1, nrounds = 100, objective = "reg:squarederror")
xgb.importance(feature_names = colnames(X), model = xgb_model4)
# 预测可视化
predictions_q_SWB <- predict(xgb_model4, dtrain)
# 制作数据框用于绘图
results_q_SWB <- data.frame(
  actual = y,
  predicted = predictions_q_SWB
)
```

#合并四个小提琴图
```{r}
# 合并数据
results_q_SGPS$type <- "SGPS"
results_q_phq$type <- "PHQ"
results_q_gad$type <- "GAD"
results_q_SWB$type <- "SWB"
all_results_q <- bind_rows(results_q_SGPS, results_q_phq, results_q_gad, results_q_SWB)

# 绘制小提琴图
ggplot(all_results_q, aes(x = type, y = residuals)) +
  geom_violin(fill = "lightgoldenrod1", color = "black", alpha = 0.7) +
  geom_boxplot(width = 0.1, outlier.color = "red", outlier.size = 1, alpha = 0.5) +
  labs(title = "Distribution of Questionnaire Residuals for Different Metrics",
       x = "Metric",
       y = "Residuals (Actual - Predicted)") +
  theme_minimal()
```

```{r}
# 绘制散点图
ggplot(all_results_q, aes(x = actual, y = predicted, color = type)) +
  geom_point(alpha = 0.6) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +  # 理想线
  facet_wrap(~type) +  # 按类型分面
  labs(title = "Predicted vs Actual (Questionnaire)",
       x = "Actual Values",
       y = "Predicted Values") +
  theme_minimal() +
  theme(legend.position = "none")
```

#认知任务
```{r}
#SGPS
X <- as.matrix(pca_task_scores[, c("Dim.1", "Dim.2", "Dim.3", "Dim.4", "Dim.5")])
y <- health_var$SGPS
dtrain <- xgb.DMatrix(data = X, label = y)
xgb_model5 <- xgboost(data = dtrain, max_depth = 6, eta = 0.1, nrounds = 100, objective = "reg:squarederror")
xgb.importance(feature_names = colnames(X), model = xgb_model5)
# 预测可视化
predictions_task_SGPS <- predict(xgb_model5, dtrain)
results_task_SGPS <- data.frame(
  actual = y,
  predicted = predictions_task_SGPS
)
results_task_SGPS$residuals <- results_task_SGPS$actual - results_task_SGPS$predicted
```

```{r}
#phq
X <- as.matrix(pca_task_scores[, c("Dim.1", "Dim.2", "Dim.3", "Dim.4", "Dim.5")])
y <- health_var$phq
dtrain <- xgb.DMatrix(data = X, label = y)
xgb_model6 <- xgboost(data = dtrain, max_depth = 6, eta = 0.1, nrounds = 100, objective = "reg:squarederror")
xgb.importance(feature_names = colnames(X), model = xgb_model6)
# 预测可视化
predictions_task_phq <- predict(xgb_model6, dtrain)
results_task_phq <- data.frame(
  actual = y,
  predicted = predictions_task_phq
)
results_task_phq$residuals <- results_task_phq$actual - results_task_phq$predicted
```


```{r}
#gad
X <- as.matrix(pca_task_scores[, c("Dim.1", "Dim.2", "Dim.3", "Dim.4", "Dim.5")])
y <- health_var$gad
dtrain <- xgb.DMatrix(data = X, label = y)
xgb_model7 <- xgboost(data = dtrain, max_depth = 6, eta = 0.1, nrounds = 100, objective = "reg:squarederror")
xgb.importance(feature_names = colnames(X), model = xgb_model7)
# 预测可视化
predictions_task_gad <- predict(xgb_model7, dtrain)
results_task_gad <- data.frame(
  actual = y,
  predicted = predictions_task_gad
)
results_task_gad$residuals <- results_task_gad$actual - results_task_gad$predicted
```

```{r}
#SWB
X <- as.matrix(pca_task_scores[, c("Dim.1", "Dim.2", "Dim.3", "Dim.4", "Dim.5")])
y <- health_var$SWB
dtrain <- xgb.DMatrix(data = X, label = y)
xgb_model8 <- xgboost(data = dtrain, max_depth = 6, eta = 0.1, nrounds = 100, objective = "reg:squarederror")
xgb.importance(feature_names = colnames(X), model = xgb_model8)
# 预测可视化
predictions_task_SWB <- predict(xgb_model8, dtrain)
results_task_SWB <- data.frame(
  actual = y,
  predicted = predictions_task_SWB
)
results_task_SWB$residuals <- results_task_SWB$actual - results_task_SWB$predicted
```
#合并绘图
```{r}
# 合并数据
results_task_SGPS$type <- "SGPS"
results_task_phq$type <- "PHQ"
results_task_gad$type <- "GAD"
results_task_SWB$type <- "SWB"
all_results_task <- bind_rows(results_task_SGPS, results_task_phq, results_task_gad, results_task_SWB)

# 绘制小提琴图
ggplot(all_results_task, aes(x = type, y = residuals)) +
  geom_violin(fill = "orange", color = "black", alpha = 0.7) +
  geom_boxplot(width = 0.1, outlier.color = "red", outlier.size = 1, alpha = 0.5) +
  labs(title = "Distribution of Task Residuals for Different Metrics",
       x = "Metric",
       y = "Residuals (Actual - Predicted)") +
  theme_minimal()
```

```{r}
# 绘制散点图
ggplot(all_results_task, aes(x = actual, y = predicted, color = type)) +
  geom_point(alpha = 0.6) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +  # 理想线
  facet_wrap(~type) +  # 按类型分面
  labs(title = "Predicted vs Actual (TASK)",
       x = "Actual Values",
       y = "Predicted Values") +
  theme_minimal() +
  theme(legend.position = "none")
```

#Bifactor模型
```{r}
# 自动确定模型因子数量
fa_parallel <- fa.parallel(data_z, fa = "fa", fm = "minres", n.iter = 100)
nfactors <- fa_parallel$nfact  # 推荐因子数量
# 进行 EFA
efa_result <- fa(r = cor(data_z), nfactors = nfactors, fm = "minres", rotate = "oblimin")
# 打印因子分析结果，查看因子载荷
print(efa_result)
# 提取因子载荷矩阵
loadings <- as.data.frame(efa_result$loadings)
# 根据因子载荷动态生成 bifactor 模型公式
threshold <- 0.3  # 因子载荷的阈值
model_formula <- ""

for (factor_idx in 1:nfactors) {
  # 检查因子索引是否在范围内
  if (factor_idx <= ncol(loadings$x)) {
    # 提取当前因子相关的条目
    factor_items <- rownames(loadings$x)[abs(loadings$x[, factor_idx]) > threshold]
    factor_name <- paste0("F", factor_idx)
    
    # 为模型公式添加条目
    if (length(factor_items) > 0) {
      model_formula <- paste0(
        model_formula,
        factor_name, " =~ ", paste(factor_items, collapse = " + "), "\n"
      )
    }
  }
}

# 添加通用因子
general_factor_items <- rownames(loadings$x)
model_formula <- paste0(
  "I =~ ", paste(general_factor_items, collapse = " + "), "\n", 
  model_formula
)
# 打印生成的模型公式
cat(model_formula)

# 模型
model_formula <- '
  # 总体因子
  I =~ selfclarity_1 + selfclarity_2 + selfclarity_3 + selfclarity_4 + selfclarity_5 + selfclarity_6 + selfclarity_7 + selfclarity_8 + selfclarity_9 + selfclarity_10 + selfclarity_11 + selfclarity_12 + LOT_1 + LOT_2 + LOT_3 + LOT_4 + LOT_5 + LOT_6 + IPC_1 + IPC_2 + IPC_3 + IPC_4 + IPC_5 + IPC_6 + IPC_7 + IPC_8 + ses_1 + ses_2 + ses_3 + ses_4 + ses_5 + ses_6 + ses_7 + ses_8 + ses_9 + ses_10 + coreself_1 + coreself_2 + coreself_3 + coreself_4 + coreself_5 + coreself_6 + coreself_7 + coreself_8 + coreself_9 + coreself_10 + NPI1 + NPI2 + NPI3 + NPI4 + NPI5 + NPI6 + NPI7 + NPI8 + NPI9 + NPI10 + NPI11 + NPI12 + NPI13 + NPI14 + NPI15 + hsns_1 + hsns_2 + hsns_3 + hsns_4 + hsns_5 + hsns_6 + hsns_7 + hsns_8 + hsns_9 + hsns_10 + MorIden_1 + MorIden_2 + MorIden_3 + MorIden_4 + MorIden_5 + MorIden_6 + MorIden_7 + MorIden_8 + MorIden_9 + MorIden_10 + moralSeImag_1 + moralSeImag_2 + moralSeImag_3 + moralSeImag_4 + moralSeImag_5 + moralSeImag_6 + moralSeImag_7 + moralSeImag_8 + moralSeImag_9 + sde_1 + sde_2 + sde_3 + sde_4 + sde_5 + sde_6 + sde_7 + sde_8 + sde_9 + sde_10 + sde_11 + sde_12 + sde_13 + sde_14 + sde_15 + sde_16 + sde_17 + sde_18 + sde_19 + sde_20 + IM_1 + IM_2 + IM_3 + IM_4 + IM_5 + IM_6 + IM_7 + IM_8 + IM_9 + IM_10 + IM_11 + IM_12 + IM_13 + IM_14 + IM_15 + IM_16 + IM_17 + IM_18 + IM_19 + IM_20 + Ability + Attraction + Wealth + Social + Moral + ability_ALT_rt + moral_ALT_rt + ability_ALT_d + moral_ALT_d + ability_IAT + moral_IAT + ability_SRET_EW + moral_SRET_EW + ability_SRET_rt + moral_SRET_rt + ability_SRET_RJ1_d + moral_SRET_RJ1_d + ability_SRET_RJ2_d + moral_SRET_RJ2_d
  
  # 特定因子
F1 =~ LOT_3 + LOT_5 + IPC_6 + ses_1 + ses_2 + ses_3 + ses_4 + ses_5 + ses_6 + ses_7 + ses_8 + ses_9 + ses_10 + coreself_1 + coreself_2 + coreself_3 + coreself_4 + coreself_5 + coreself_6 + coreself_7 + coreself_8 + coreself_9 + coreself_10 + hsns_1 + sde_9 + sde_19 + Ability
F2 =~ selfclarity_1 + selfclarity_2 + selfclarity_3 + selfclarity_4 + selfclarity_5 + selfclarity_6 + selfclarity_7 + selfclarity_8 + selfclarity_9 + selfclarity_10 + selfclarity_11 + selfclarity_12 + LOT_2 + NPI7 + sde_5 + sde_7 + sde_20
F3 =~ moralSeImag_1 + moralSeImag_2 + moralSeImag_3 + moralSeImag_4 + moralSeImag_5 + moralSeImag_6 + moralSeImag_7 + moralSeImag_8 + moralSeImag_9 + Moral
F4 =~ IM_2 + IM_3 + IM_4 + IM_6 + IM_7 + IM_9 + IM_10 + IM_11 + IM_12 + IM_13 + IM_14 + IM_15 + IM_16 + IM_17 + IM_18 + IM_19 + IM_20
F5 =~ selfclarity_3 + selfclarity_10 + LOT_2 + coreself_2 + coreself_3 + hsns_3 + hsns_5 + hsns_6 + hsns_7 + hsns_8 + sde_2 + sde_6 + sde_10 + sde_12 + sde_14 + sde_18 + IM_1 + IM_3 + IM_5 + IM_7 + IM_15 + IM_19
F6 =~ NPI1 + NPI2 + NPI3 + NPI4 + NPI5 + NPI6 + NPI8 + NPI10 + NPI11 + NPI15 + Social
F7 =~ IPC_7 + MorIden_2 + MorIden_5 + MorIden_6 + MorIden_7 + MorIden_8 + MorIden_9 + MorIden_10
F8 =~ IPC_1 + IPC_2 + IPC_7 + sde_9 + sde_13 + ability_SRET_EW
F9 =~ hsns_9 + MorIden_3 + sde_1 + sde_3 + sde_11 + sde_15 + sde_17 + sde_19
F10 =~ ability_SRET_rt + moral_SRET_rt + ability_SRET_RJ2_d + moral_SRET_RJ2_d
F11 =~ ability_ALT_rt + moral_ALT_rt + ability_ALT_d + moral_ALT_d
F12 =~ MorIden_1 + MorIden_3 + IM_10

  # 因子之间的协方差
  #F1 ~~ F2 + F3
  #F4 ~~ F5 + F6
  #F7 ~~ F8
'
```

```{r}
# 拟合模型
model_formula = lavaan::sem(model_formula, 
                      data=data_z, 
                      #ordered = colnames(data_z), 
                      std.lv = TRUE, 
                      fixed.x = F,
                      orthogonal = TRUE)
# 输出模型拟合结果和标准化估计
summary(model_formula , standardized = TRUE, fit.measures = TRUE)
semPaths(model_formula , what = 'std', fade = F)

```

```{r}
model_formula <- cfa(model_formula, data_z,orthogonal=TRUE) # 进行CFA
summary(model_formula ,fit.measures="TRUE") # 显示总体结果
fitMeasures(model_formula ,fit.measures="all", baseline.model=NULL) # 显示所有拟合指数
standardizedSolution(model_formula) # 显示标准化的结果
reliability_results <- semTools::reliability(model_formula)# 计算AVE、CR（Composite Reliability）等值
semPaths(model_formula, bifactor = "G", 
         title=F, what = "std", residuals = FALSE,
         intercepts = FALSE, layout = "tree2",
         label.cex=1, edge.label.cex=0.1, font=2,  
         edge.color="black", fixedStyle = c("black",1),freeStyle = c("black",1),esize = 0.01,
         rotation=1)                                                                 # 画图,bifactor指定哪个因素为bifactor；rotation控制方向，取值为1/2/3/4
```








